{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "CnUcRYecmFYK",
        "Ye0L5yvsmY9Y",
        "fKZwqLX0qfDB"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YNg6pEapexER",
        "outputId": "3acb4ec9-554c-47dd-e29c-433b86c17927"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import textwrap\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from gensim.models import Word2Vec\n",
        "from sklearn.cluster import KMeans\n",
        "from scipy.spatial import distance\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sumy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "raKkVa9PjPrQ",
        "outputId": "654197ba-6851-44d7-9bbe-aa5f87c2a2f0"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: sumy in /usr/local/lib/python3.10/dist-packages (0.11.0)\n",
            "Requirement already satisfied: docopt<0.7,>=0.6.1 in /usr/local/lib/python3.10/dist-packages (from sumy) (0.6.2)\n",
            "Requirement already satisfied: nltk>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from sumy) (3.8.1)\n",
            "Requirement already satisfied: pycountry>=18.2.23 in /usr/local/lib/python3.10/dist-packages (from sumy) (22.3.5)\n",
            "Requirement already satisfied: breadability>=0.1.20 in /usr/local/lib/python3.10/dist-packages (from sumy) (0.1.20)\n",
            "Requirement already satisfied: requests>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from sumy) (2.27.1)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (from breadability>=0.1.20->sumy) (4.0.0)\n",
            "Requirement already satisfied: lxml>=2.0 in /usr/local/lib/python3.10/dist-packages (from breadability>=0.1.20->sumy) (4.9.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.0.2->sumy) (1.2.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk>=3.0.2->sumy) (4.65.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.0.2->sumy) (2022.10.31)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>=3.0.2->sumy) (8.1.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from pycountry>=18.2.23->sumy) (67.7.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.7.0->sumy) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.7.0->sumy) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.7.0->sumy) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.7.0->sumy) (1.26.15)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rouge"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vsoX_UVIR_Fw",
        "outputId": "9b0047e1-b94a-4a7d-e666-8b1484dc4efa"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: rouge in /usr/local/lib/python3.10/dist-packages (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from rouge) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('bbc_text_cls.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ynyNlS7Ie6eu",
        "outputId": "e3d05617-3eab-4888-a2b9-635bbb1e6ece"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text    labels\n",
              "0  Ad sales boost Time Warner profit\\n\\nQuarterly...  business\n",
              "1  Dollar gains on Greenspan speech\\n\\nThe dollar...  business\n",
              "2  Yukos unit buyer faces loan claim\\n\\nThe owner...  business\n",
              "3  High fuel prices hit BA's profits\\n\\nBritish A...  business\n",
              "4  Pernod takeover talk lifts Domecq\\n\\nShares in...  business"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-10c83aa1-cea6-454a-8bfa-026d993eeb4f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Ad sales boost Time Warner profit\\n\\nQuarterly...</td>\n",
              "      <td>business</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Dollar gains on Greenspan speech\\n\\nThe dollar...</td>\n",
              "      <td>business</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Yukos unit buyer faces loan claim\\n\\nThe owner...</td>\n",
              "      <td>business</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>High fuel prices hit BA's profits\\n\\nBritish A...</td>\n",
              "      <td>business</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Pernod takeover talk lifts Domecq\\n\\nShares in...</td>\n",
              "      <td>business</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-10c83aa1-cea6-454a-8bfa-026d993eeb4f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-10c83aa1-cea6-454a-8bfa-026d993eeb4f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-10c83aa1-cea6-454a-8bfa-026d993eeb4f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc = df[df.labels == 'business']['text'].sample(random_state=24)"
      ],
      "metadata": {
        "id": "yHvPBtO2g1f4"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def wrap(x):\n",
        "  return textwrap.fill(x, replace_whitespace=False, fix_sentence_endings=True)"
      ],
      "metadata": {
        "id": "wndSkf4Hg4Kt"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(wrap(doc.iloc[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4yHdGrvQg8tS",
        "outputId": "2e958bdb-e4bb-4e42-a901-1b7adee5255c"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Singapore growth at 8.1% in 2004\n",
            "\n",
            "Singapore's economy grew by 8.1% in\n",
            "2004, its best performance since 2000, figures from the trade ministry\n",
            "show.\n",
            "\n",
            "The advance, the second-fastest in Asia after China, was led by\n",
            "growth of 13.1% in the key manufacturing sector.  However, a slower-\n",
            "than-expected fourth quarter points to more modest growth for the\n",
            "trade-driven economy in 2005 as global technology demand falls back.\n",
            "Slowdowns in the US and China could hit electronics exports, while the\n",
            "tsunami disaster may effect the service sector.\n",
            "\n",
            "Economic growth is\n",
            "set to halve in Singapore this year to between 3% and 5%. In the\n",
            "fourth quarter, the city state's gross domestic product (GDP) rose at\n",
            "an annual rate of 2.4%. That was up from the third quarter, when it\n",
            "fell 3.0%, but was well below analyst forecasts.  \"I am surprised at\n",
            "the weak fourth quarter number.  The main drag came from electronics,\"\n",
            "said Lian Chia Liang, economist at JP Morgan Chase.  Singapore's\n",
            "economy had contracted over the summer, weighed down by soaring oil\n",
            "prices.  The economy's poor performance in the July to September\n",
            "period followed four consecutive quarters of double-digit growth as\n",
            "Singapore bounced back strongly from the effects of the deadly Sars\n",
            "virus in 2003.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Text Rank Summary**\n",
        "used for comparing different models\n"
      ],
      "metadata": {
        "id": "CnUcRYecmFYK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sumy.summarizers.text_rank import TextRankSummarizer\n",
        "from sumy.summarizers.lsa import LsaSummarizer\n",
        "from sumy.parsers.plaintext import PlaintextParser\n",
        "from sumy.nlp.tokenizers import Tokenizer\n",
        "summarizer = TextRankSummarizer()\n",
        "parser = PlaintextParser.from_string(\n",
        "    doc.iloc[0].split(\"\\n\", 1)[1],\n",
        "    Tokenizer(\"english\"))\n",
        "summary = summarizer(parser.document, sentences_count=5)\n",
        "sum_=str()\n",
        "for s in summary:\n",
        "  sum_+=str(s)\n",
        "sum_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "_isvs94ejI3O",
        "outputId": "e90e4163-bea8-495d-e42c-7c7568029b14"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"The advance, the second-fastest in Asia after China, was led by growth of 13.1% in the key manufacturing sector.However, a slower-than-expected fourth quarter points to more modest growth for the trade-driven economy in 2005 as global technology demand falls back.Slowdowns in the US and China could hit electronics exports, while the tsunami disaster may effect the service sector.In the fourth quarter, the city state's gross domestic product (GDP) rose at an annual rate of 2.4%.The economy's poor performance in the July to September period followed four consecutive quarters of double-digit growth as Singapore bounced back strongly from the effects of the deadly Sars virus in 2003.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **TF-IDF Score to Summerize Text**"
      ],
      "metadata": {
        "id": "Ye0L5yvsmY9Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "featurizer = TfidfVectorizer(stop_words=stopwords.words('english'),norm='l1')\n",
        "X = featurizer.fit_transform(sents)\n",
        "def get_sentence_score(tfidf_row):\n",
        "  # return the average of the non-zero values\n",
        "  # of the tf-idf vector representation of a sentence\n",
        "  x = tfidf_row[tfidf_row != 0]\n",
        "  return x.mean()\n",
        "\n",
        "\n",
        "def summarize_tfidf(text):\n",
        "  # extract sentences\n",
        "  sents = nltk.sent_tokenize(text)\n",
        "\n",
        "  # perform tf-idf\n",
        "  X = featurizer.fit_transform(sents)\n",
        "\n",
        "  # compute scores for each sentence\n",
        "  scores = np.zeros(len(sents))\n",
        "  for i in range(len(sents)):\n",
        "    score = get_sentence_score(X[i,:])\n",
        "    scores[i] = score\n",
        "  \n",
        "  # sort the scores\n",
        "  sort_idx = np.argsort(-scores)\n",
        "\n",
        "  # print summary\n",
        "  sum_=str()\n",
        "  for i in sort_idx[:5]:\n",
        "    #print(wrap(\"%.2f: %s\" % (scores[i], sents[i])))\n",
        "    sum_+=sents[i]\n",
        "  return sum_"
      ],
      "metadata": {
        "id": "NlEq2TmuhIVg"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sum_tfidf=summarize_tfidf(doc.iloc[0].split(\"\\n\", 1)[1])"
      ],
      "metadata": {
        "id": "dnwmrdxgh9Lk"
      },
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(wrap(sum_tfidf))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZIY-yRwDioJr",
        "outputId": "e0f8a0e8-643c-4d97-fc2b-211237d2989b"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"I am surprised at the weak fourth quarter number.Economic growth is\n",
            "set to halve in Singapore this year to between 3% and 5%.That was up\n",
            "from the third quarter, when it fell 3.0%, but was well below analyst\n",
            "forecasts.Singapore's economy had contracted over the summer, weighed\n",
            "down by soaring oil prices.The advance, the second-fastest in Asia\n",
            "after China, was led by growth of 13.1% in the key manufacturing\n",
            "sector.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Cosine Similarity**"
      ],
      "metadata": {
        "id": "fKZwqLX0qfDB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def summarize_cosine(text, factor = 0.15):\n",
        "  # extract sentences\n",
        "  sents = nltk.sent_tokenize(text)\n",
        "\n",
        "  # perform tf-idf\n",
        "  featurizer = TfidfVectorizer(\n",
        "      stop_words=stopwords.words('english'),\n",
        "      norm='l1')\n",
        "  X = featurizer.fit_transform(sents)\n",
        "\n",
        "  # compute similarity matrix\n",
        "  S = cosine_similarity(X)\n",
        "\n",
        "  # normalize similarity matrix\n",
        "  S /= S.sum(axis=1, keepdims=True)\n",
        "\n",
        "  # uniform transition matrix\n",
        "  U = np.ones_like(S) / len(S)\n",
        "\n",
        "  # smoothed similarity matrix\n",
        "  S = (1 - factor) * S + factor * U\n",
        "\n",
        "  # find the limiting / stationary distribution\n",
        "  eigenvals, eigenvecs = np.linalg.eig(S.T)\n",
        "\n",
        "  # compute scores\n",
        "  scores = eigenvecs[:,0] / eigenvecs[:,0].sum()\n",
        "  \n",
        "  # sort the scores\n",
        "  sort_idx = np.argsort(-scores)\n",
        "\n",
        "  # print summary\n",
        "  sum_=str()\n",
        "  for i in sort_idx[:5]:\n",
        "    #print(wrap(\"%.2f: %s\" % (scores[i], sents[i])))\n",
        "    sum_+=sents[i]\n",
        "  return sum_"
      ],
      "metadata": {
        "id": "6R8XsVPnmkTu"
      },
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sum_cos=summarize_cosine(doc.iloc[0].split(\"\\n\", 1)[1], factor = 0.15)"
      ],
      "metadata": {
        "id": "xVkaxb32o9Ci"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(wrap(sum_cos))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j6rtGgKrpaen",
        "outputId": "4a774b02-deed-486a-8d86-36530f653767"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "However, a slower-than-expected fourth quarter points to more modest\n",
            "growth for the trade-driven economy in 2005 as global technology\n",
            "demand falls back.The economy's poor performance in the July to\n",
            "September period followed four consecutive quarters of double-digit\n",
            "growth as Singapore bounced back strongly from the effects of the\n",
            "deadly Sars virus in 2003.\"I am surprised at the weak fourth quarter\n",
            "number.\n",
            "Singapore's economy grew by 8.1% in 2004, its best performance\n",
            "since 2000, figures from the trade ministry show.Economic growth is\n",
            "set to halve in Singapore this year to between 3% and 5%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **K-Mean Clustering**"
      ],
      "metadata": {
        "id": "mcvlgdhWqlWR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = nltk.sent_tokenize(doc.iloc[0].split(\"\\n\", 1)[1])\n",
        "corpus = []\n",
        "for i in range(len(sentence)):\n",
        "    sen = re.sub('[^a-zA-Z]', \" \", sentence[i])  \n",
        "    sen = sen.lower()                            \n",
        "    sen = sen.split()                         \n",
        "    sen = ' '.join([i for i in sen if i not in stopwords.words('english')])   \n",
        "    corpus.append(sen)\n",
        "\n",
        "all_words = [i.split() for i in corpus]\n",
        "model = Word2Vec(all_words, min_count=1,vector_size=300)\n",
        "\n",
        "sent_vector=[]\n",
        "for i in corpus:  \n",
        "    plus=0\n",
        "    for j in i.split():\n",
        "        plus+= model.wv[j]\n",
        "    plus = plus/len(i.split())\n",
        "    sent_vector.append(plus)\n",
        "\n",
        "n_clusters = 5\n",
        "kmeans = KMeans(n_clusters, init = 'k-means++', random_state = 42)\n",
        "y_kmeans = kmeans.fit_predict(sent_vector)\n",
        "\n",
        "my_list=[]\n",
        "for i in range(n_clusters):\n",
        "    my_dict={} \n",
        "    for j in range(len(y_kmeans)):\n",
        "        if y_kmeans[j]==i:\n",
        "            my_dict[j] =  distance.euclidean(kmeans.cluster_centers_[i],sent_vector[j])\n",
        "    min_distance = min(my_dict.values())\n",
        "    my_list.append(min(my_dict, key=my_dict.get))\n",
        "                            \n",
        "for i in sorted(my_list):\n",
        "    sum_kmean=sentence[i]\n",
        "\n",
        "print(wrap(sum_kmean))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dr0kIEyOqkoN",
        "outputId": "25f1cb0b-6099-4f9c-e4d5-7cec91b20ff0"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The economy's poor performance in the July to September period\n",
            "followed four consecutive quarters of double-digit growth as Singapore\n",
            "bounced back strongly from the effects of the deadly Sars virus in\n",
            "2003.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Evaluation**\n",
        "Bleu Score"
      ],
      "metadata": {
        "id": "SgpF7MRUqCd3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "t1=word_tokenize(sum_)\n",
        "t2=word_tokenize(sum_tfidf)\n",
        "t3=word_tokenize(sum_cos)\n",
        "t4=word_tokenize(sum_kmean)\n",
        "print(sentence_bleu(t1,t2,weights=(1,0,0,0)))\n",
        "print(sentence_bleu(t1,t3,weights=(1,0,0,0)))\n",
        "print(sentence_bleu(t1,t4,weights=(1,0,0,0)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AwQM0nkIjkPm",
        "outputId": "f30c0189-8538-487c-a56e-2d2044419c2e"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.07317073170731705\n",
            "0.0660377358490566\n",
            "0.02941176470588235\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 2-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from rouge import Rouge\n",
        "rouge = Rouge()\n",
        "s=rouge.get_scores(sum_kmean, sum_)\n",
        "s[0]['rouge-1']['f']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7DtauqgR5cn",
        "outputId": "043db731-f7e3-4358-a01c-618b118bd896"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.49122806646968303"
            ]
          },
          "metadata": {},
          "execution_count": 135
        }
      ]
    }
  ]
}